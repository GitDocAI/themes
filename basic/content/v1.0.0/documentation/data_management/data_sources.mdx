# Data Sources

Data Sources are a fundamental aspect of UTMStack, providing the necessary input for the platform's comprehensive security services. As a Unified Threat Management Platform, UTMStack delivers essential security services including Log Management (SIEM), Threat Detection and Response, Real-time Correlation, Reporting, Compliance Reporting, Cloud Monitoring, SaaS Monitoring (Office 365, Google Cloud), Vulnerability Management, network/host IDS/IPS, Endpoint Protection Integration, Identity Activity Management (tracking user activity), Automated and On-demand Incident Response, Forensics Analysis, and Artificial Intelligence Security.

Effective management of data sources is critical for collecting the logs and other relevant information required to power these features and maintain robust cybersecurity posture.

## Key Components for Data Collection

Within the UTMStack documentation, the management of data input is organized into distinct areas:

### Data Sources
This section focuses on the overall configuration and management of the various origins from which security data and logs are collected into the UTMStack platform. It serves as the primary interface for defining and overseeing where your critical security information originates.

### Collectors
Collectors are integral components that work in conjunction with data sources. They are responsible for actively gathering and forwarding data from the defined sources to the UTMStack system, ensuring that logs and other relevant security telemetry are ingested for analysis and processing.

## Further Documentation

For detailed guides on configuring and managing these components, specific documentation pages are available:
*   Data Sources
*   Collectors

## Summary

Data Sources and their associated Collectors are vital for integrating external security information into UTMStack. They enable the platform to perform its extensive range of security services, from log management and threat detection to compliance reporting and AI-driven security, by ensuring a steady and organized flow of operational data.